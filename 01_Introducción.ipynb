{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar variables de entorno desde .env\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()  # Esto cargará las variables definidas en el archivo .env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiWA3U55HQxZ"
      },
      "source": [
        "# **Introducción**\n",
        "\n",
        "https://python.langchain.com/docs/introduction/\n",
        "\n",
        "## **¿Qué es Langchain?**\n",
        "\n",
        "**Langchain** es un marco para desarrollar aplicaciones alimentadas por modelos LLM.\n",
        "\n",
        "Langchain simplifica cada etapa del ciclo de vida de la aplicación LLM:\n",
        "\n",
        "- **Desarrollo**  Cree sus aplicaciones usando los [componentes](https://python.langchain.com/docs/concepts/) open-source de Langchain e [integraciones de terceros](https://python.langchain.com/docs/integrations/providers/) . Puede usar [LangGraph](https://python.langchain.com/docs/concepts/architecture/#langgraph) para construir agentes con estado con la transmisión de primera clase y el apoyo humano en el bucle.\n",
        "- **Producción**: Use [LangSmith](https://docs.smith.langchain.com/) para inspeccionar, monitorear y evaluar sus aplicaciones, para que pueda optimizar e implementar continuamente con confianza.\n",
        "- **Despliegue**: Convierta sus aplicaciones de Langgraph en API listas para la producción y asistentes con la [Plataforma LangGraph](https://langchain-ai.github.io/langgraph/cloud/) .\n",
        "\n",
        "![Diagrama que describe la organización jerárquica del marco Langchain, mostrando las partes interconectadas en múltiples capas.](https://python.langchain.com/svg/langchain_stack_112024_dark.svg)\n",
        "\n",
        "Langchain implementa una interfaz estándar para modelos de lenguaje grandes y tecnologías relacionadas, como la modelos de embeddings y almacenes vectoriales (vector stores), y se integra con cientos de proveedores. Ver la página de [integración con proveedores](https://python.langchain.com/docs/integrations/providers/) para ver más.\n",
        "\n",
        "**Seleccionar [modelo de chat](https://python.langchain.com/docs/integrations/chat/) : (Ejemplo con Groq)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar variables de entorno desde .env\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()  # Esto cargará las variables definidas en el archivo .env\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "print(\"API Key cargada correctamente\" if api_key else \"No se encontró la API Key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp4o4eusHQxb"
      },
      "source": [
        "```\n",
        "pip install -qU \"langchain[groq]\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb3jVhlaRNeZ"
      },
      "source": [
        "`-qU` significa quiet y Update, para que no genere salida y actualice el módulo si ya estuviera instalado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnpag-2ePney"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdoD1TEpHQxb"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
        "from langchain.chat_models import init_chat_model\n",
        "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZN8hHw4HQxc",
        "outputId": "4da22dff-074a-4255-9b7b-c5878725a0e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='La construcción del Monasterio de El Escorial, ubicado en San Lorenzo de El Escorial, Madrid, España, comenzó en 1563 y finalizó en 1584, lo que significa que tardó aproximadamente 21 años en construirse.\\n\\nLa construcción del monasterio fue iniciada por Felipe II de España en memoria de sus padres, Carlos V y Isabel de Portugal, y estaba destinado a ser un monumento a la memoria de la familia real española. El proyecto fue encargado al arquitecto Juan de Toledo y el escultor Alonso Berruguete, y posteriormente fue continuado por Juan de Herrera, que se convirtió en el arquitecto principal del proyecto.\\n\\nLa construcción del monasterio fue un proceso lento y complejo, que requirió la labor de miles de trabajadores y la utilización de materiales como piedra, mármol y bronce. El resultado fue un edificio majestuoso y monumental que ha sido considerado uno de los mejores ejemplos de arquitectura renacentista en España.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 237, 'prompt_tokens': 25, 'total_tokens': 262, 'completion_time': 0.210427985, 'prompt_time': 0.005888747, 'queue_time': 0.063986107, 'total_time': 0.216316732}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--df1eb4a6-2039-4ad3-8b63-ef194bdf0303-0', usage_metadata={'input_tokens': 25, 'output_tokens': 237, 'total_tokens': 262})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"¿Cuántos años tardó en construirse El Escorial?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZe7fLlwHQxc"
      },
      "source": [
        "\n",
        "\n",
        "# **Arquitectura**\n",
        "\n",
        "El framework Langchain consta de múltiples bibliotecas de código abierto. Leer más en la página de [Arquitectura](https://python.langchain.com/docs/concepts/architecture/).\n",
        "\n",
        "- **`langchain-core`**: Abstracciones base para modelos de chat y otros componentes.\n",
        "- **Paquetes de integración** (p.ej `langchain-openai`, `langchain-anthropic`, etc.): Las integraciones importantes se han dividido en paquetes livianos que son co-mantenidos por el equipo de Langchain y los desarrolladores de integración.\n",
        "- **`langchain`**: Cadenas, agentes y estrategias de recuperación que conforman la arquitectura cognitiva de una aplicación.\n",
        "- **`langchain-community`**: Integraciones de terceros que se mantienen en la comunidad.\n",
        "- **`langgraph`**: Marco de orquestación para combinar los componentes de Langchain en aplicaciones listas para la producción con persistencia, transmisión y otras características clave. Ver [Documentación de LangGraph](https://langchain-ai.github.io/langgraph/) .\n",
        "\n",
        "\n",
        "¿Cómo hacer…?[**How-to guides**](https://python.langchain.com/docs/how_to/)\n",
        "\n",
        "[Here](https://python.langchain.com/docs/how_to/) you’ll find short answers to “How do I….?” types of questions. These how-to guides don’t cover topics in depth – you’ll find that material in the [Tutorials](https://python.langchain.com/docs/tutorials/) and the [API Reference](https://python.langchain.com/api_reference/). However, these guides will help you quickly accomplish common tasks using [chat models](https://python.langchain.com/docs/how_to/#chat-models), [vector stores](https://python.langchain.com/docs/how_to/#vector-stores), and other common LangChain components.\n",
        "\n",
        "Check out [LangGraph-specific how-tos here](https://langchain-ai.github.io/langgraph/how-tos/).\n",
        "\n",
        "# [**Conceptual guide**](https://python.langchain.com/docs/concepts/)\n",
        "\n",
        "Introductions to all the key parts of LangChain you’ll need to know! [Here](https://python.langchain.com/docs/concepts/) you'll find high level explanations of all LangChain concepts.\n",
        "\n",
        "For a deeper dive into LangGraph concepts, check out [this page](https://langchain-ai.github.io/langgraph/concepts/).\n",
        "\n",
        "# [**Integrations**](https://python.langchain.com/docs/integrations/providers/)\n",
        "\n",
        "LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [chat models](https://python.langchain.com/docs/integrations/chat/), [vector stores](https://python.langchain.com/docs/integrations/vectorstores/), or other LangChain components from a specific provider, check out our growing list of [integrations](https://python.langchain.com/docs/integrations/providers/).\n",
        "\n",
        "# [**API reference**](https://python.langchain.com/api_reference/)\n",
        "\n",
        "Head to the reference section for full documentation of all classes and methods in the LangChain Python packages.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
