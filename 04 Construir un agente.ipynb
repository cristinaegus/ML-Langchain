{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno desde .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # Esto cargará las variables definidas en el archivo .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCMWJHkRz5DB"
   },
   "source": [
    "# **Construir un agente**\n",
    "\n",
    "Langchain posibilita la creación de [agentes](https://python.langchain.com/docs/concepts/agents/), o sistemas que usan [LLMS](https://python.langchain.com/docs/concepts/chat_models/) como motores de razonamiento para determinar qué acciones tomar y las entradas necesarias para realizar la acción. Después de ejecutar acciones, los resultados se pueden volver a alimentar a la LLM para determinar si se necesitan más acciones o si está bien terminar. Esto a menudo se logra a través del llamado de herramientas [tool-calling](https://python.langchain.com/docs/concepts/tool_calling/).\n",
    "\n",
    "En este tutorial construiremos un agente que pueda interactuar con un motor de búsqueda. Podrá hacer preguntas de este agente, verlo llamar a la herramienta de búsqueda y tener conversaciones con ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8423,
     "status": "ok",
     "timestamp": 1752750246906,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "XnIs4gRkZEdo"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-core langgraph>0.2.27 langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9th9rNuY7zm"
   },
   "source": [
    "\n",
    "\n",
    "# **LangSmith**\n",
    "\n",
    "Muchas de las aplicaciones que construye con Langchain contendrán múltiples pasos con múltiples invocaciones de llamadas LLM. A medida que estas aplicaciones se vuelven cada vez más complejas, se vuelve crucial poder inspeccionar lo que está sucediendo exactamente dentro de su cadena o agente. La mejor manera de hacer esto es con [LangSmith](https://smith.langchain.com/).\n",
    "\n",
    "Después de registrarse en el enlace de arriba, asegúrese de establecer sus variables de entorno para comenzar a registrar las trazas:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gkPjzoYHACx"
   },
   "source": [
    "```\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "export LANGSMITH_PROJECT=\"default\" # or any other project name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTgqRZa0HACx"
   },
   "source": [
    "\n",
    "\n",
    "O, si en un cuaderno, puede configurarlos con:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15020,
     "status": "ok",
     "timestamp": 1752749949628,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "MuDAwrkdHACy",
    "outputId": "9181084c-e2be-4ef2-f67a-0355059cc7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your LangSmith API key (optional): ··········\n",
      "Enter your LangSmith Project Name (default = \"pr-glossy-thought-54\"): ··········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"pr-glossy-thought-54\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"pr-glossy-thought-54\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFf6Cot8z5DL"
   },
   "source": [
    "# **Tavily**\n",
    "\n",
    "Para instalar Tavily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8374,
     "status": "ok",
     "timestamp": 1752749976322,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "BScOvRyuz5DM",
    "outputId": "35d15e3c-ec4f-413c-be94-6b63e90a876c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-tavily\n",
      "  Downloading langchain_tavily-0.2.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (3.11.15)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.26)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.68)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2025.7.14)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.2.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.3.1)\n",
      "Downloading langchain_tavily-0.2.9-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: langchain-tavily\n",
      "Successfully installed langchain-tavily-0.2.9\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRnBn1-zz5DM"
   },
   "source": [
    "[Tavily](https://python.langchain.com/docs/integrations/tools/tavily_search/) es un motor de búsqueda. Para usarlo, deberá obtener y establecer una clave API:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRoDuBEpz5DM"
   },
   "source": [
    "bash\n",
    "export TAVILY_API_KEY=\"...\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdCnUubiz5DM"
   },
   "source": [
    "\n",
    "\n",
    "O, si está en un cuaderno, puede configurarlo con:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4182,
     "status": "ok",
     "timestamp": 1752749991807,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "wriY7Yoxz5DM",
    "outputId": "558bcdc2-42fa-42ce-d32e-8efece70791e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "··········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V_6WuElz5DM"
   },
   "source": [
    "\n",
    "\n",
    "# **Definir herramientas**\n",
    "\n",
    "Primero necesitamos crear las herramientas que queremos usar. Nuestra principal herramienta de elección será [Tavily](https://python.langchain.com/docs/integrations/tools/tavily_search/) - Un motor de búsqueda. Podemos usar el [Langchain-Tavily](https://pypi.org/project/langchain-tavily/) [paquete de integración](https://python.langchain.com/docs/concepts/architecture/#integration-packages) dedicado para usar fácilmente el motor de búsqueda Tavily como herramienta con Langchain.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1752750036401,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "p6JM6ECOz5DM",
    "outputId": "62567660-7d03-44a2-d266-2e9b5ac8839f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Qué tiempo hace hoy en Bilbao?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.eltiempo.es/bilbao.html?v=por_hora', 'title': 'El Tiempo en Bilbao, Vizcaya a 14 días - Previsión por horas', 'content': 'El tiempo en Bilbao · Hoy. 11:00. Icono. 25°. 0 mm. 0%. 6 km/h. 12:00. Icono. 27°. 0 mm. 0%. 7 km/h. 13:00. Icono. 28°. 0 mm · Mañana. 00:00. Icono. 20°. 0 mm. 20', 'score': 0.853046, 'raw_content': None}, {'url': 'https://www.clima.com/espana/euskadi/bilbao', 'title': 'Clima en Bilbao hoy y pronóstico del tiempo a 14 días', 'content': 'Viento. 16 km/h. Ráfagas. 23 km/h. Lluvia. 0 mm. Nieve. 0 cm. Nubes. 55%. Prob. de precipitación. 20%. Radiación UV. -. Humedad. 76%. Presión. 1020 hPa.', 'score': 0.8005209, 'raw_content': None}], 'response_time': 1.67}\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "search = TavilySearch(max_results=2)\n",
    "search_results = search.invoke(\"Qué tiempo hace hoy en Bilbao?\")\n",
    "print(search_results)\n",
    "# Se pueden crear otras herramientas si se quiere.\n",
    "# Una vez que sabemos que esta funciona, la ponemos en una lista y la añadiremos al modelo más tarde.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15XN61dBz5DM"
   },
   "source": [
    "\n",
    "\n",
    "En muchas aplicaciones, es posible que desee definir herramientas personalizadas. Langchain admite la creación de herramientas personalizadas a través de funciones de Python y otros medios. Consulte a guíal [Cómo crear herramientas](https://python.langchain.com/docs/how_to/custom_tools/) para obtener más detalles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICK9Opl28xPS"
   },
   "source": [
    "# **Uso de modelos del lenguaje**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFcOZ2et8n9P"
   },
   "source": [
    "Langchain admite muchos modelos de idioma diferentes que puede usar indistintamente: ¡seleccione el que desea usar a continuación!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6774,
     "status": "ok",
     "timestamp": 1752750066556,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "ax894SRk8n9Q"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24364,
     "status": "ok",
     "timestamp": 1752750090920,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "7I4AbCyX8n9R",
    "outputId": "e54719ca-914a-4d8c-a2f7-2272f4e85b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Groq: ··········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6MSMnJ3z5DN"
   },
   "source": [
    "\n",
    "\n",
    "Puede llamar al modelo de idioma pasando una lista de mensajes. Por defecto, la respuesta es un objeto string `content`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1752750096405,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "p5cbcsjbz5DN",
    "outputId": "ba9e667f-ffb2-49cb-9799-7455fb36a24e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hola! ¡Bienvenido! ¿Cómo estás?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hola!\"\n",
    "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "response.text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KR5-C8kz5DN"
   },
   "source": [
    "\n",
    "\n",
    "Ahora podemos ver cómo permitir que este modelo realice llamadas de herramientas. Para habilitarlas podemos usar `.bind_tools` para dar al modelo de idioma conocimiento de estas herramientas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1752750109456,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "DS3cp1fmz5DN"
   },
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJEJBGoOz5DN"
   },
   "source": [
    "\n",
    "\n",
    "Ahora podemos llamar al modelo. Primero llamemos con un mensaje normal y veamos cómo responde. Podemos mirar ambos campos `content` y`tool_calls`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1752750191941,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "zPxi8r0-z5DN",
    "outputId": "b93a2a4d-6b8d-41af-e288-a35d85aa9c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message content: ¡Hola Aitor! Me alegra conocerte. Bilbao es una ciudad hermosa, ¿qué te gusta hacer allí? ¿Tienes algún lugar favorito o actividad que te guste hacer en tu ciudad natal?\n",
      "\n",
      "Tool calls: []\n"
     ]
    }
   ],
   "source": [
    "query = \"Me llamo Aitor y vivo en Bilbao\"\n",
    "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "print(f\"Message content: {response.text()}\\n\")\n",
    "print(f\"Tool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzAR_9Q4z5DN"
   },
   "source": [
    "\n",
    "\n",
    "Ahora, intentemos llamarlo con alguna entrada que esperaría que se llame a una herramienta.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1752750201889,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "pfvOyul7z5DQ",
    "outputId": "1ff3ada5-d3a1-4fd7-aa9c-8aa63a8cfe8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message content: \n",
      "\n",
      "Tool calls: [{'name': 'tavily_search', 'args': {'query': 'weather forecast Bilbao this weekend', 'search_depth': 'advanced', 'time_range': 'week', 'topic': 'general'}, 'id': 'rqtda7b39', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"Busca cuál va a ser el tiempo de este fin de semana en Bilbao\"\n",
    "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "print(f\"Message content: {response.text()}\\n\")\n",
    "print(f\"Tool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM7AGWJdz5DR"
   },
   "source": [
    "\n",
    "\n",
    "Podemos ver que ahora no hay contenido de texto, ¡pero hay una llamada de herramienta! Quiere que llamemos a la herramienta de búsqueda de Tavily.\n",
    "\n",
    "Esto aún no está llamando a esa herramienta, solo nos está diciendo que lo puede hacer. Para llamarlo realmente, queremos crear nuestro agente.\n",
    "\n",
    "# **Crea el agente**\n",
    "\n",
    "Ahora que hemos definido las herramientas y el LLM, podemos crear el agente. Estaremos usando [Langgraph](https://python.langchain.com/docs/concepts/architecture/#langgraph) para construir el agente. Actualmente, estamos utilizando una interfaz de alto nivel para construir el agente, pero lo bueno de Langgraph es que esta interfaz de alto nivel está respaldada por una API de bajo nivel y altamente controlable en caso de que desee modificar la lógica del agente.\n",
    "\n",
    "Ahora, podemos inicializar el agente con el LLM y las herramientas.\n",
    "\n",
    "Tenga en cuenta que le estamos pasando `model`, no `model_with_tools`. Eso es porque `create_react_agent`llamará `.bind_tools`para nosotros debajo del capó.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1752750256592,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "aNT4YWKpz5DR"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUvNP6XBz5DR"
   },
   "source": [
    "\n",
    "\n",
    "**Referencia de API:** [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)\n",
    "\n",
    "# **Ejecutar el agente**\n",
    "\n",
    "¡Ahora podemos ejecutar el agente con algunas consultas! Tenga en cuenta que por ahora, todos estos son **apátrida** Consultas (no recordará las interacciones anteriores). Tenga en cuenta que el agente devolverá el **final** Estado al final de la interacción (que incluye cualquier entrada, veremos más adelante sobre cómo obtener solo las salidas).\n",
    "\n",
    "Primero, veamos cómo responde cuando no hay necesidad de llamar a una herramienta:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1752750290968,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "57bg3QMZz5DR",
    "outputId": "a8627ab9-04c5-4ed5-8929-e556e2a48836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hola!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<hello>\n",
      "{\n",
      "  \"response\": \"¡Hola! Soy un asistente automatizado. ¿En qué puedo ayudarte hoy?\"\n",
      "}\n",
      "</hello>\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"Hola!\"}\n",
    "response = agent_executor.invoke({\"messages\": [input_message]})\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tqD2CoKz5DR"
   },
   "source": [
    "\n",
    "\n",
    "Para ver exactamente lo que está sucediendo debajo del capó (y para asegurarse de que no llame una herramienta) podemos echar un vistazo al [Trace de Langsmith](https://smith.langchain.com/public/28311faa-e135-4d6a-ab6b-caecf6482aaa/r)\n",
    "\n",
    "Probémoslo ahora en un ejemplo en el que debería invocar la herramienta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3204,
     "status": "ok",
     "timestamp": 1752750327518,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "1K_ydOHbz5DR",
    "outputId": "5084d3ae-b1fc-43fc-9c8e-291e0d4fe0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Busca el tiempo que va a hacer este sábado en Bilbao, España\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (tzg97n0x8)\n",
      " Call ID: tzg97n0x8\n",
      "  Args:\n",
      "    query: weather Bilbao Saturday\n",
      "    search_depth: advanced\n",
      "    time_range: day\n",
      "    topic: general\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"weather Bilbao Saturday\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.timeanddate.com/weather/spain/bilbao/hourly\", \"title\": \"Hourly forecast for Bilbao, Vizcaya, Spain - Weather - Time and Date\", \"content\": \"| 12:00 pm |  | 73 °F | Overcast. | 74 °F | 4 mph | ↑ | 76% | 3% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n|  |  |  |  |  |  |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| \\\\ Updated Thursday, July 17, 2025 9:42:23 am Bilbao time - Weather by CustomWeather, © 2025 | | | | | | | | | | [...] | 4:00 pm |  | 83 °F | Scattered clouds. | 85 °F | 7 mph | ↑ | 59% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 5:00 pm |  | 81 °F | Broken clouds. | 83 °F | 7 mph | ↑ | 62% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 6:00 pm |  | 80 °F | Mostly cloudy. | 82 °F | 7 mph | ↑ | 64% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 7:00 pm |  | 77 °F | Cloudy. | 79 °F | 7 mph | ↑ | 69% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 8:00 pm |  | 75 °F | Overcast. | 76 °F | 6 mph | ↑ | 73% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) | [...] | 7:00 am |  | 69 °F | Overcast. | 69 °F | 2 mph | ↑ | 86% | 1% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 8:00 am |  | 69 °F | Overcast. | 69 °F | 2 mph | ↑ | 85% | 1% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 9:00 am |  | 70 °F | Overcast. | 70 °F | 2 mph | ↑ | 83% | 2% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 10:00 am |  | 71 °F | Overcast. | 72 °F | 3 mph | ↑ | 80% | 2% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 11:00 am |  | 72 °F | Overcast. | 73 °F | 3 mph | ↑ | 78% | 3% | 0.00\\\" (snow) 0.00\\\" (rain) |\", \"score\": 0.7352811, \"raw_content\": null}, {\"url\": \"https://www.timeanddate.com/weather/spain/bilbao\", \"title\": \"Weather for Bilbao, Vizcaya, Spain - Time and Date\", \"content\": \"| Feels Like | 67°F | 63°F | 56°F | 59°F | 69°F | 63°F | 56°F |\\n| Wind Speed | 10 mph | 6 mph | 3 mph | 2 mph | 8 mph | 3 mph | 3 mph |\\n| Wind Direction | NW ↑ | NW ↑ | SW ↑ | W ↑ | NNW ↑ | NNW ↑ | S ↑ |\\n| Humidity | 66% | 73% | 88% | 83% | 58% | 76% | 87% |\\n| Dew Point | 55°F | 54°F | 52°F | 53°F | 54°F | 55°F | 52°F |\\n| Visibility | 7 mi | 4 mi | 6 mi | 6 mi | 9 mi | 8 mi | 7 mi |\\n| Probability of Precipitation | 28% | 15% | 0% | 4% | 0% | 2% | 0% | [...] Scroll right to see more\\n|  | Monday | Tuesday | Wednesday |\\n| --- | --- | --- | --- |\\n|  | Afternoon | Evening | Night | Morning | Afternoon | Evening | Night |\\n| Forecast | Image 12 | Image 13 | Image 14 | Image 15 | Image 16 | Image 17 | Image 18 |\\n| Temperature | 67°F | 63°F | 56°F | 59°F | 69°F | 63°F | 56°F |\\n|  | Passing showers. Overcast. | Isolated thunder­storms. Cloudy. | Partly cloudy. | Sunny. | Scatt­erred clouds. | Broken clouds. | Broken clouds. | [...] | Amount of Rain | 0.03\\\" | 0.02\\\" | - | - | - | - | - |\\n|  Updated Monday, May 19, 2025 9:42:55 am Bilbao time - Weather by CustomWeather, © 2025 |\", \"score\": 0.49846253, \"raw_content\": null}], \"response_time\": 1.31}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the result provided by the tool, I can see that it yielded a weather forecast for Bilbao, Spain for Saturday. The forecast shows a mix of overcast and cloudy conditions throughout the day, with a high temperature of 83°F (28°C) and a low of 69°F (21°C). There is also a chance of precipitation, but it is not expected to be significant.\n",
      "\n",
      "To provide a more specific answer to the user's question, I will extract the relevant information from the result. Here is the answer:\n",
      "\n",
      "\"Saturday's weather in Bilbao, Spain is expected to be mostly overcast, with a high temperature of 83°F (28°C) and a low of 69°F (21°C). There is a chance of precipitation, but it is not expected to be significant. The forecast is based on hourly data from Time and Date.\"\n",
      "\n",
      "Note that the answer is based on the result provided by the tool and may be subject to change.\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"Busca el tiempo que va a hacer este sábado en Bilbao, España\"}\n",
    "response = agent_executor.invoke({\"messages\": [input_message]})\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFBR7KiUz5DR"
   },
   "source": [
    "\n",
    "\n",
    "Podemos ver el [Trace de Langsmith](https://smith.langchain.com/public/f520839d-cd4d-4495-8764-e32b548e235d/r) Para asegurarse de que esté llamando a la herramienta de búsqueda de manera efectiva.\n",
    "\n",
    "# Streaming\n",
    "\n",
    "Hemos visto cómo se puede llamar al agente con `.invoke`Para obtener una respuesta final. Si el agente ejecuta múltiples pasos, esto puede llevar un tiempo. Para mostrar un progreso intermedio, podemos transmitir mensajes a medida que ocurren.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50711,
     "status": "ok",
     "timestamp": 1752750399630,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "ddMdysK5z5DR",
    "outputId": "78c37f76-ddba-466e-cbbb-3a3914505e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Busca el tiempo que va a hacer este sábado en Bilbao, España\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (pdfgznd4e)\n",
      " Call ID: pdfgznd4e\n",
      "  Args:\n",
      "    query: weather Bilbao Saturday\n",
      "    search_depth: advanced\n",
      "    time_range: day\n",
      "    topic: general\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"weather Bilbao Saturday\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.timeanddate.com/weather/spain/bilbao/hourly\", \"title\": \"Hourly forecast for Bilbao, Vizcaya, Spain - Weather - Time and Date\", \"content\": \"| 12:00 pm |  | 73 °F | Overcast. | 74 °F | 4 mph | ↑ | 76% | 3% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n|  |  |  |  |  |  |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| \\\\ Updated Thursday, July 17, 2025 9:42:23 am Bilbao time - Weather by CustomWeather, © 2025 | | | | | | | | | | [...] | 4:00 pm |  | 83 °F | Scattered clouds. | 85 °F | 7 mph | ↑ | 59% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 5:00 pm |  | 81 °F | Broken clouds. | 83 °F | 7 mph | ↑ | 62% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 6:00 pm |  | 80 °F | Mostly cloudy. | 82 °F | 7 mph | ↑ | 64% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 7:00 pm |  | 77 °F | Cloudy. | 79 °F | 7 mph | ↑ | 69% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 8:00 pm |  | 75 °F | Overcast. | 76 °F | 6 mph | ↑ | 73% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) | [...] | 7:00 am |  | 69 °F | Overcast. | 69 °F | 2 mph | ↑ | 86% | 1% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 8:00 am |  | 69 °F | Overcast. | 69 °F | 2 mph | ↑ | 85% | 1% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 9:00 am |  | 70 °F | Overcast. | 70 °F | 2 mph | ↑ | 83% | 2% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 10:00 am |  | 71 °F | Overcast. | 72 °F | 3 mph | ↑ | 80% | 2% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 11:00 am |  | 72 °F | Overcast. | 73 °F | 3 mph | ↑ | 78% | 3% | 0.00\\\" (snow) 0.00\\\" (rain) |\", \"score\": 0.7352811, \"raw_content\": null}, {\"url\": \"https://www.timeanddate.com/weather/spain/bilbao\", \"title\": \"Weather for Bilbao, Vizcaya, Spain - Time and Date\", \"content\": \"| Feels Like | 67°F | 63°F | 56°F | 59°F | 69°F | 63°F | 56°F |\\n| Wind Speed | 10 mph | 6 mph | 3 mph | 2 mph | 8 mph | 3 mph | 3 mph |\\n| Wind Direction | NW ↑ | NW ↑ | SW ↑ | W ↑ | NNW ↑ | NNW ↑ | S ↑ |\\n| Humidity | 66% | 73% | 88% | 83% | 58% | 76% | 87% |\\n| Dew Point | 55°F | 54°F | 52°F | 53°F | 54°F | 55°F | 52°F |\\n| Visibility | 7 mi | 4 mi | 6 mi | 6 mi | 9 mi | 8 mi | 7 mi |\\n| Probability of Precipitation | 28% | 15% | 0% | 4% | 0% | 2% | 0% | [...] Scroll right to see more\\n|  | Monday | Tuesday | Wednesday |\\n| --- | --- | --- | --- |\\n|  | Afternoon | Evening | Night | Morning | Afternoon | Evening | Night |\\n| Forecast | Image 12 | Image 13 | Image 14 | Image 15 | Image 16 | Image 17 | Image 18 |\\n| Temperature | 67°F | 63°F | 56°F | 59°F | 69°F | 63°F | 56°F |\\n|  | Passing showers. Overcast. | Isolated thunder­storms. Cloudy. | Partly cloudy. | Sunny. | Scatt­erred clouds. | Broken clouds. | Broken clouds. | [...] | Amount of Rain | 0.03\\\" | 0.02\\\" | - | - | - | - | - |\\n|  Updated Monday, May 19, 2025 9:42:55 am Bilbao time - Weather by CustomWeather, © 2025 |\", \"score\": 0.49846253, \"raw_content\": null}], \"response_time\": 1.2}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (fyzkcbqxe)\n",
      " Call ID: fyzkcbqxe\n",
      "  Args:\n",
      "    follow_up_questions: None\n",
      "    query: weather Bilbao Saturday\n",
      "    search_depth: advanced\n",
      "    time_range: day\n",
      "    topic: general\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"weather Bilbao Saturday\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.timeanddate.com/weather/spain/bilbao/hourly\", \"title\": \"Hourly forecast for Bilbao, Vizcaya, Spain - Weather - Time and Date\", \"content\": \"| 12:00 pm |  | 73 °F | Overcast. | 74 °F | 4 mph | ↑ | 76% | 3% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n|  |  |  |  |  |  |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| \\\\ Updated Thursday, July 17, 2025 9:42:23 am Bilbao time - Weather by CustomWeather, © 2025 | | | | | | | | | | [...] | 4:00 pm |  | 83 °F | Scattered clouds. | 85 °F | 7 mph | ↑ | 59% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 5:00 pm |  | 81 °F | Broken clouds. | 83 °F | 7 mph | ↑ | 62% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 6:00 pm |  | 80 °F | Mostly cloudy. | 82 °F | 7 mph | ↑ | 64% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 7:00 pm |  | 77 °F | Cloudy. | 79 °F | 7 mph | ↑ | 69% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 8:00 pm |  | 75 °F | Overcast. | 76 °F | 6 mph | ↑ | 73% | 0% | 0.00\\\" (snow) 0.00\\\" (rain) | [...] | 7:00 am |  | 69 °F | Overcast. | 69 °F | 2 mph | ↑ | 86% | 1% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 8:00 am |  | 69 °F | Overcast. | 69 °F | 2 mph | ↑ | 85% | 1% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 9:00 am |  | 70 °F | Overcast. | 70 °F | 2 mph | ↑ | 83% | 2% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 10:00 am |  | 71 °F | Overcast. | 72 °F | 3 mph | ↑ | 80% | 2% | 0.00\\\" (snow) 0.00\\\" (rain) |\\n| 11:00 am |  | 72 °F | Overcast. | 73 °F | 3 mph | ↑ | 78% | 3% | 0.00\\\" (snow) 0.00\\\" (rain) |\", \"score\": 0.7352811, \"raw_content\": null}, {\"url\": \"https://www.timeanddate.com/weather/spain/bilbao\", \"title\": \"Weather for Bilbao, Vizcaya, Spain - Time and Date\", \"content\": \"| Feels Like | 67°F | 63°F | 56°F | 59°F | 69°F | 63°F | 56°F |\\n| Wind Speed | 10 mph | 6 mph | 3 mph | 2 mph | 8 mph | 3 mph | 3 mph |\\n| Wind Direction | NW ↑ | NW ↑ | SW ↑ | W ↑ | NNW ↑ | NNW ↑ | S ↑ |\\n| Humidity | 66% | 73% | 88% | 83% | 58% | 76% | 87% |\\n| Dew Point | 55°F | 54°F | 52°F | 53°F | 54°F | 55°F | 52°F |\\n| Visibility | 7 mi | 4 mi | 6 mi | 6 mi | 9 mi | 8 mi | 7 mi |\\n| Probability of Precipitation | 28% | 15% | 0% | 4% | 0% | 2% | 0% | [...] Scroll right to see more\\n|  | Monday | Tuesday | Wednesday |\\n| --- | --- | --- | --- |\\n|  | Afternoon | Evening | Night | Morning | Afternoon | Evening | Night |\\n| Forecast | Image 12 | Image 13 | Image 14 | Image 15 | Image 16 | Image 17 | Image 18 |\\n| Temperature | 67°F | 63°F | 56°F | 59°F | 69°F | 63°F | 56°F |\\n|  | Passing showers. Overcast. | Isolated thunder­storms. Cloudy. | Partly cloudy. | Sunny. | Scatt­erred clouds. | Broken clouds. | Broken clouds. | [...] | Amount of Rain | 0.03\\\" | 0.02\\\" | - | - | - | - | - |\\n|  Updated Monday, May 19, 2025 9:42:55 am Bilbao time - Weather by CustomWeather, © 2025 |\", \"score\": 0.49846253, \"raw_content\": null}], \"response_time\": 1.36}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the hourly forecast for Saturday in Bilbao, Spain, the weather is expected to be mostly cloudy with temperatures ranging from 73°F to 83°F. There is a chance of scattered clouds and broken clouds throughout the day, with a low probability of precipitation. The humidity is expected to be around 66% to 76%, with a wind speed of around 4-7 mph. Overall, it is expected to be a pleasant day with mild temperatures and minimal precipitation chance.\n"
     ]
    }
   ],
   "source": [
    "for step in agent_executor.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSB7vm5Mz5DS"
   },
   "source": [
    "\n",
    "\n",
    "# **Streaming tokens**\n",
    "\n",
    "Además de devolver el flujo de mensajes, también es útil devolver los tokens. Podemos hacer esto especificando `stream_mode=\"messages\"`.\n",
    "\n",
    "> ℹ️ A continuación usamos `message.text()`, que requiere `langchain-core>=0.3.37`.\n",
    ">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47378,
     "status": "ok",
     "timestamp": 1752750470117,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "5tghE5w4z5DS",
    "outputId": "b31df192-bcd8-4e52-9fbc-2d2a95b9ee25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based| on| the| output| of| the| tool| call| \"|g|080|13|b|0|x|\",| I| can| see| that| the| query| \"|weather| Bil|bao| Saturday|\"| yielded| some| results|.| However|,| the| output| is| quite| lengthy| and| seems| to| be| a| mix| of| weather| information| for| Bil|bao| and| other| cities| in| Spain|,| as| well| as| some| extra| content|.\n",
      "\n",
      "|To| provide| a| more| concise| answer|,| I| can| extract| the| relevant| information| for| Bil|bao|.| According| to| the| output|,| the| weather| forecast| for| Bil|bao| on| Saturday| is| not| explicitly| provided|,| but| we| can| see| that| the| average| temperature| in| July| is| around| |15|-|25|°C| (|59|-|77|°F|).\n",
      "\n",
      "|If| you| would| like| a| more| accurate| and| concise| weather| forecast| for| Bil|bao| on| Saturday|,| I| can| suggest| an| alternative| tool| call| or| provide| a| direct| response| based| on| general| weather| patterns| in| the| region|.|"
     ]
    }
   ],
   "source": [
    "for step, metadata in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, stream_mode=\"messages\"\n",
    "):\n",
    "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
    "        print(text, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2E-306qz5DS"
   },
   "source": [
    "\n",
    "\n",
    "# **Agregar memoria**\n",
    "\n",
    "Como se mencionó anteriormente, este agente no tiene un estado almacenado. Esto significa que no recuerda las interacciones anteriores. Para darle memoria, debemos pasar en un checkpointer. Al pasar un checkpointer, también tenemos que pasarle un `thread_id` al invocar el agente (para que sepa de qué hilo/conversación reanudar).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752750496387,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "sbTzhC7Lz5DS"
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLt-brmdz5DS"
   },
   "source": [
    "\n",
    "\n",
    "**Referencia de API:** [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/?_gl=1*1p10qdy*_ga*MTE2NzUyNjc2Ny4xNzUyNjU0NTQ2*_ga_47WX3HKKY2*czE3NTI2NjI1ODkkbzQkZzEkdDE3NTI2NjI3MzYkajYwJGwwJGgw#langgraph.checkpoint.memory.MemorySaver)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752750661151,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "Pkpg1SDXz5DS"
   },
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"abc765\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1752750711007,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "T6vbuNvsz5DS",
    "outputId": "0f60d0e4-a8a2-44c8-9696-5b183afc9e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hola! Soy de Bilbao. Qué hora es?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Hola! Como soy una inteligencia artificial, no tengo acceso a información en tiempo real sobre la hora actual. Sin embargo, puedo decirte que si estás en Bilbao, España, la hora actual depende de la hora del día y la zona horaria. ¿Podrías ser más específico sobre qué hora te gustaría saber?\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"Hola! Soy de Bilbao. Qué hora es?\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7979,
     "status": "ok",
     "timestamp": 1752750733146,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "t4ThDYwoz5DS",
    "outputId": "be4c84dc-3d45-4b9a-8e93-018f70b5aaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Busca el tiempo que va a hacer este sábado en la ciudad donde vivo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (hvt38ndhx)\n",
      " Call ID: hvt38ndhx\n",
      "  Args:\n",
      "    query: weather forecast for Bilbao, Spain this Saturday\n",
      "    search_depth: advanced\n",
      "    time_range: day\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"weather forecast for Bilbao, Spain this Saturday\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.ventusky.com/37.450;-5.780\", \"title\": \"Location - Weather Forecast Maps | Ventusky\", \"content\": \"# Ventusky: Weather Forecast Maps\\n\\nHail\\n\\n# Location\\n\\n|  |\\n| --- |\\n| 33 °C |\\n|  |\\n| Wind  9 km/h |\\n\\n|  |  |\\n| --- | --- |\\n| Humidity | 32 % |\\n\\nCalculated from nearby stations (12:30 2025/07/17)\\n\\n## Weather for the next 24 hours [...] clear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nhigh clouds\\nhigh clouds\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nhigh clouds\\nmostly cloudy\\nhigh clouds\\nhigh clouds\\nclear sky\\nclear sky\\nclear sky\\n\\n## Forecast\\n\\nclear sky with few clouds\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\nclear sky [...] clear sky\\nclear sky\\nhigh clouds\\nhigh clouds\\nclear sky\\nclear sky\\nclear sky\\nclear sky\\n\\n## Meteogram\\n\\n|  |\\n| --- |\\n| 45 |\\n| 40 |\\n| 35 |\\n| 30 |\\n| 25 |\\n| 20 |\\n| 15 |\", \"score\": 0.10912552, \"raw_content\": null}, {\"url\": \"https://insights.som.yale.edu/insights/creating-the-bilbao-effect\", \"title\": \"Creating the Bilbao Effect | Yale Insights\", \"content\": \"The Bilbao I grew up in had a lot of industry, a lot of activity. It was not a tourist destination because it was a very polluted city. In the later part of the 20th century, steel making and ship building underwent a structural decline.\\n\\nOtaola: I remember how gray and industrial the city was. How the river smelled bad and was nearly solid. [...] Krens: Bilbao had a substantial, even a meteoric impact, but those are kind of once a century events. If even that. (Source: The Week in Art podcast)\\n\\nHarrity: The museum was a project within a much larger strategic plan. The Basque put Bilbao on the global map. They created a destination for tourism. Here we are 27 years later, still looking at the economic return and the cultural return. [...] Harrity: I worked on great projects at the Met. I worked with Frank Gehry again in Philadelphia, but Bilbao ignited a spark for everybody involved. For the Basque, for the Guggenheim, for Frank, we gave birth to this extraordinary project that transformed not only the region, but certainly my life, as well.\\n\\nEditor’s Note: This oral history is based on interviews conducted between February and April of 2025. Additional quotations have been used from existing published sources cited above.\", \"score\": 0.097467884, \"raw_content\": null}], \"response_time\": 4.64}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the result of the previous tool call, I can see that the forecast for Bilbao, Spain this Saturday is likely to be clear sky with few clouds. However, I would like to clarify with you whether you would like me to provide more specific information about the weather, such as the temperature or wind speed.\n",
      "\n",
      "Additionally, I noticed that the result also mentioned the Bilbao Effect, which is a term used to describe the transformation of Bilbao's cityscape and economy through the construction of the Guggenheim Museum. If you are interested in learning more about this topic, I can provide some information.\n",
      "\n",
      "Please let me know how I can assist you further.\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"Busca el tiempo que va a hacer este sábado en la ciudad donde vivo\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvzBFQkJz5DS"
   },
   "source": [
    "\n",
    "\n",
    "Ejemplo [Trace de Langsmith](https://smith.langchain.com/public/fa73960b-0f7d-4910-b73d-757a12f33b2b/r)\n",
    "\n",
    "Si desea comenzar una nueva conversación, todo lo que tiene que hacer es cambiar el `thread_id`usado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "executionInfo": {
     "elapsed": 26081,
     "status": "error",
     "timestamp": 1752750786809,
     "user": {
      "displayName": "Aitor Donado",
      "userId": "08246046509718212083"
     },
     "user_tz": -120
    },
    "id": "cgvhr9U8z5DS",
    "outputId": "b9e77b5d-84d9-4203-8217-4e44f768b66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (3ccc6d6c4)\n",
      " Call ID: 3ccc6d6c4\n",
      "  Args:\n",
      "    query: What's my name?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"What's my name?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.youtube.com/watch?v=U0CGsw6h60k&pp=0gcJCfwAo7VqN5tD\", \"title\": \"Rihanna - What's My Name? ft. Drake - YouTube\", \"content\": \"Rihanna - What's My Name? ft. Drake\\n\\nRihannaVEVO\\n3664749 likes\\n1072186442 views\\n12 Nov 2010\\nREMASTERED IN HD!\\nGet Rihanna’s eighth studio album ANTI now:\\nDownload on TIDAL: http://smarturl.it/downloadANTI\\nStream on TIDAL: http://smarturl.it/streamANTIdlx\\nDownload on iTunes: http://smarturl.it/dlxANTI\\nDownload on Google Play: http://smarturl.it/ANTIdlxgp\\nDownload on Amazon: http://geni.us/amzANTI \\n\\nMusic video by Rihanna performing What's My Name?. (C) 2010 The Island Def Jam Music Group\\n#Rihanna #WhatsMyName #Remastered\\n\\n#VEVOCertified on January 23, 2011. http://www.vevo.com/certified http://www.youtube.com/vevocertified\\n186322 comments\", \"score\": 0.63316137, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=1cIn69VsV9g\", \"title\": \"What's My Name (Red Version) (From \\\"Descendants - YouTube\", \"content\": \"\\\"Descendants/Zombies: Worlds Collide Tour\\\" is a one-of-a-kind interactive live concert experience coming to arenas across North America in\", \"score\": 0.48703963, \"raw_content\": null}], \"response_time\": 0.91}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (b38104j4b)\n",
      " Call ID: b38104j4b\n",
      "  Args:\n",
      "    exclude_domains: ['youtube.com']\n",
      "    include_favicon: True\n",
      "    include_images: True\n",
      "    query: What's my name?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"What's my name?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [\"https://ca.billboard.com/media-library/rihanna-ft-drake-what-s-my-name.jpg?id=50595439&width=980&quality=90\", \"https://i.pinimg.com/originals/42/7f/7d/427f7d8116c550b1f6180a4910053b6a.jpg\", \"https://i.ytimg.com/vi/_dyvXcv3ej0/maxresdefault.jpg\", \"https://f.ptcdn.info/497/082/000/s4xio923fi1Zw2a7X5IdB-o.png\", \"http://www.aelitaxtranslate.com/wp-content/uploads/2016/01/rihanna-whats-my-name-feat-drake.jpg\"], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/What%27s_My_Name_(Descendants_song)\", \"title\": \"What's My Name (Descendants song)\", \"content\": \"\\\"What's My Name\\\" is a song performed by China Anne McClain, Thomas Doherty, and Dylan Playfair that was released as a single on June 2, 2017, by Walt Disney\", \"score\": 0.5923135, \"raw_content\": null, \"favicon\": \"https://en.wikipedia.org/static/favicon/wikipedia.ico\"}, {\"url\": \"https://open.spotify.com/track/53xAT6jud1w0NqlBjSW4VB\", \"title\": \"What's My Name - song and lyrics by China Anne McClain ...\", \"content\": \"Lyrics. This is all hands on deck. Calling out to lost boys and girls. I'm gettin' tired of the disrespect. We won't stop 'til we rule the world.\", \"score\": 0.45638612, \"raw_content\": null, \"favicon\": \"https://open.spotifycdn.com/cdn/images/favicon32.b64ecc03.png\"}], \"response_time\": 2.15}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-28-2913691551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"thread_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"xyz123\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"What's my name?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m for step in agent_executor.stream(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_message\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ):\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2532\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2534\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2535\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2536\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/chat_agent_executor.py\u001b[0m in \u001b[0;36mcall_model\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStateSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunnableConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mStateSchema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_input_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_runnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;31m# add agent name to the AIMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5429\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5430\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5431\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5432\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5433\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m         return cast(\n\u001b[1;32m    377\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    962\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 results.append(\n\u001b[0;32m--> 782\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    783\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1029\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_groq/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         }\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         )\n\u001b[0;32m-> 1232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m     def patch(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m                     \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                     self._sleep_for_retry(\n\u001b[0m\u001b[1;32m   1021\u001b[0m                         \u001b[0mretries_taken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretries_taken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                         \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_sleep_for_retry\u001b[0;34m(self, retries_taken, max_retries, options, response)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retrying request to %s in %f seconds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     def _process_response(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
    "input_message = {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzSOJvWyz5DS"
   },
   "source": [
    "\n",
    "\n",
    "# **Conclusión**\n",
    "\n",
    "En este comienzo rápido cubrimos cómo crear un agente simple. Luego hemos mostrado cómo transmitir una respuesta, ¡no solo con los pasos intermedios, sino también los tokens! También hemos agregado memoria para poder tener una conversación coherente. ¡Los agentes son un tema complejo con mucho que aprender!\n",
    "\n",
    "Para obtener más información sobre los agentes, consulte la documentación de [Langgraph](https://python.langchain.com/docs/concepts/architecture/#langgraph). Ésta tiene su propio conjunto de conceptos, tutoriales y guías de instrucciones.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
